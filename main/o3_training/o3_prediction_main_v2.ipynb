{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 및 Geometric 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/user/workdir/CMAQ_Emulator/main')\n",
    "\n",
    "# 모델 라이브러리\n",
    "from src.model.cmaqnet_unet import build_model\n",
    "\n",
    "# 학습 및 처리/분석 관련 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Geometric 및 시각화 라이브러리\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 스케일러 설정\n",
    "import joblib\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2D Map 결과 도출을 위한 지도 파라미터 세팅\n",
    "proj = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "atob = {\n",
    "    0: 'G', 1: 'F', 2: 'K', 3: 'J', 4: 'E', 5: 'D',\n",
    "    6: 'O', 7: 'C', 8: 'A', 9: 'Q', 10: 'P', 11: 'B',\n",
    "    12: 'M', 13: 'L', 14: 'N', 15: 'I', 16: 'H'}\n",
    "region_columns = {\n",
    "    'A': 'Seoul City', 'B': 'Incheon City', 'C': 'Busan City', 'D': 'Daegu City',\n",
    "    'E': 'Gwangju City', 'F': 'Gyeonggi-do', 'G': 'Gangwon-do', 'H': 'Chungbuk-do',\n",
    "    'I': 'Chungnam-do', 'J': 'Gyeongbuk-do', 'K': 'Gyeongnam-do', 'L': 'Jeonbuk-do',\n",
    "    'M': 'Jeonnam-do', 'N': 'Jeju-do', 'O': 'Daejeon City', 'P': 'Ulsan City', 'Q': 'Sejong City'}\n",
    "\n",
    "def get_ctprvn_map() -> gpd.GeoDataFrame:\n",
    "    path = '/home/user/workdir/CMAQ_Emulator/main/resources/geom/ctp_rvn.shp'\n",
    "    ctprvn = gpd.GeoDataFrame.from_file(path, encoding='cp949')\n",
    "    ctprvn.crs = 'EPSG:5179'\n",
    "    return ctprvn\n",
    "\n",
    "def get_base_raster(ctprvn:gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    points = [Point(i, j)\n",
    "                for i in range(-180000, -180000 + 9000 * 67, 9000)\n",
    "                for j in range(-585000, -585000 + 9000 * 82, 9000)]\n",
    "    grid_data = gpd.GeoDataFrame(points, geometry='geometry', columns=['geometry'])\n",
    "    grid_data.crs = ctprvn.to_crs(proj).crs\n",
    "    grid_data.loc[:,'x_m'] = grid_data.geometry.x\n",
    "    grid_data.loc[:,'y_m'] = grid_data.geometry.y\n",
    "    grid_data.loc[:,'value'] = 0\n",
    "    grid_data.loc[:,'index'] = grid_data.index\n",
    "    return grid_data\n",
    "\n",
    "def get_region_pixel_indices() -> list:\n",
    "    ctprvn = get_ctprvn_map()\n",
    "    grid_data = get_base_raster(ctprvn)\n",
    " \n",
    "    cities = {\n",
    "        0: '강원도', 1: '경기도', 2: '경상남도', 3: '경상북도',\n",
    "        4: '광주광역시', 5: '대구광역시', 6: '대전광역시', 7: '부산광역시',\n",
    "        8: '서울특별시', 9: '세종특별자치시', 10: '울산광역시', 11: '인천광역시',\n",
    "        12: '전라남도', 13: '전라북도', 14: '제주특별자치도', 15: '충청남도',\n",
    "        16: '충청북도'\n",
    "    }\n",
    "\n",
    "    gdf_joined_loc = ['CTPRVN_CD', 'CTP_ENG_NM', 'CTP_KOR_NM', 'index_right0']\n",
    "    gdf_joined = gpd.sjoin(ctprvn, grid_data.to_crs(5179), predicate='contains')\n",
    "\n",
    "    indices = gpd.GeoDataFrame(pd.merge(\n",
    "        left=grid_data, right=gdf_joined.loc[:,gdf_joined_loc], \n",
    "        how='left', left_on='index', right_on='index_right0'\n",
    "    ), geometry='geometry').dropna()\n",
    "    pixel_indices = \\\n",
    "        [[(idx%82, idx//82) for idx in indices.loc[indices.CTP_KOR_NM==cities[region]].index.tolist()]\n",
    "         for region, _ in cities.items()]\n",
    "    return pixel_indices\n",
    "\n",
    "ctprvn = get_ctprvn_map()\n",
    "ctprvn_proj = ctprvn.to_crs(proj)\n",
    "\n",
    "# 건국대(서울대)에서 제공한 대한민국 국토 grid 정보\n",
    "grid_alloc = (\n",
    "    pd.read_csv('/home/user/workdir/CMAQ_Emulator/main/resources/geom/grid_allocation.csv') # load grid allocation data\n",
    "    .sort_values(by=['Row', 'Column', 'Ratio'], ascending=[True, True, False]) # sort by row, column, ratio\n",
    "    .drop_duplicates(subset=['Row', 'Column'], keep='first') # drop duplicates\n",
    "    .reset_index(drop=True) # reset index\n",
    ")\n",
    "\n",
    "# 정부에서 배포하는 대한민국 국토 grid 정보\n",
    "pixel_indices = get_region_pixel_indices()\n",
    "total_index = []\n",
    "for idx, grids in enumerate(pixel_indices):\n",
    "    for grid in grids:\n",
    "        total_index.append([\n",
    "            grid[1], grid[0], 100.0, atob[idx], region_columns[atob[idx]]\n",
    "        ])\n",
    "total_index = pd.DataFrame(total_index, columns=grid_alloc.columns)\n",
    "\n",
    "# 두 기관에서 주는 grid에 한두픽셀씩 비어있는 부분이 있어, 두 기관 데이터를 모두 참조하여 중복되는 픽셀을 정리 후 최종 국토 grid 정보를 취득\n",
    "grid_alloc = pd.concat([\n",
    "    grid_alloc.drop(columns=['Ratio', 'Region_Name']),\n",
    "    total_index.drop(columns=['Ratio', 'Region_Name'])\n",
    "]).sort_values(by=['Region_Code']).drop_duplicates().reset_index(drop=True)\n",
    "grid_alloc[['Row', 'Column']] = grid_alloc[['Row', 'Column']] - 1\n",
    "\n",
    "row_indices, col_indices = zip(*grid_alloc[['Row', 'Column']].values)\n",
    "offset_x, offset_y = 4500, 4500 # 지도 위치 맞추기\n",
    "\n",
    "# 마스킹 처리\n",
    "mask = np.zeros((82, 67))\n",
    "mask[row_indices, col_indices] = 1\n",
    "\n",
    "cmap_white = mpl.colormaps['jet']\n",
    "cmap_white.set_under('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터셋 로드\n",
    "dataset_2013 = pd.read_csv('/home/user/workdir/CMAQ_Emulator/main/resources/ctrl/precusor_4att_2013_v2.csv', index_col=0)\n",
    "ctrl_data = pd.concat([dataset_2013], axis=0)\n",
    "ctrl_data = ctrl_data.reset_index(drop=True).values\n",
    "emis_data = ctrl_data[:, :17*2]\n",
    "\n",
    "# 레이블 데이터 로드\n",
    "label_path_2013 = '/home/user/workdir/CMAQ_Emulator/main/datasets/concentration/2013'\n",
    "label_path = []\n",
    "for i in range(1, 120): \n",
    "    label_path.append(os.path.join(label_path_2013, '1.00', f'ACONC.{i}'))\n",
    "label_data = []\n",
    "for path in label_path:\n",
    "    with nc.Dataset(path) as f:\n",
    "        label_data.append(f.variables['O3'][:].data.squeeze())\n",
    "label_data = np.array(label_data).reshape(len(label_data), 82, 67, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 시 저장 경로\n",
    "model_path = '/home/user/workdir/CMAQ_Emulator/main/src/model/o3_prediction/final_model_main_v2'\n",
    "\n",
    "epochs = 1000  # 훈련 반복 횟수\n",
    "batch_size = 32  # 배치 크기\n",
    "test_split = 0.4  # 테스트 샘플 비율 (1=100%)\n",
    "random_seed = 42  # 랜덤 샘플링 시 고정 시드값\n",
    "\n",
    "X_emis_train, X_emis_test, y_train, y_test = train_test_split(emis_data, label_data, test_size=test_split, random_state=random_seed)\n",
    "\n",
    "y_train_shape = y_train.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "# 각 샘플을 flatten\n",
    "y_train_flat = y_train.reshape(y_train_shape[0], -1)\n",
    "y_test_flat  = y_test.reshape(y_test_shape[0], -1)\n",
    "\n",
    "# 샘플 값을 스케일링\n",
    "y_train_scaled_flat = scaler.fit_transform(y_train_flat)\n",
    "y_test_scaled_flat  = scaler.transform(y_test_flat)\n",
    "joblib.dump(scaler, '/home/user/workdir/CMAQ_Emulator/main/o3_training/o3_prediction_origin_v2.pkl')\n",
    "print(\"Scaler saved successfully.\")\n",
    "\n",
    "# 다시 원래 shape으로 복원\n",
    "y_train_scaled = y_train_scaled_flat.reshape(y_train_shape)\n",
    "y_test_scaled  = y_test_scaled_flat.reshape(y_test_shape)\n",
    "\n",
    "# Cosine Decay 스케줄 설정\n",
    "steps_per_epoch = len(X_emis_train) // batch_size \n",
    "total_steps = epochs * steps_per_epoch\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=1e-3,\n",
    "        decay_steps=total_steps,\n",
    "        alpha=0.1  # 최종 lr 비율 (0이면 최솟값이 0)\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model = build_model(\n",
    "        ctrl_dim=17*2,\n",
    "        out_channel=1,\n",
    "        hidden_size=[96, 64],   # 256, 128\n",
    "        hidden_depth=4,         # 5\n",
    "        in_filters=10,          # 64\n",
    "        kernel_size=3,\n",
    "        activation='silu',\n",
    "        dropout=0.0,\n",
    "        use_abs=True\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss=tf.keras.losses.Huber(delta=1)  # delta는 Huber 손실 전환점\n",
    "    )\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=150, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    x=[X_emis_train],\n",
    "    y=y_train_scaled,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=[[X_emis_test], y_test],\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. 전체 에포크에 대한 학습 및 검증 손실\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, history.history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. 마지막 10 에포크의 손실 (세부 분석)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    if len(epochs) >= 10:\n",
    "        last_epochs = epochs[-10:]\n",
    "        plt.plot(last_epochs, history.history['loss'][-10:], label='Training Loss', color='blue')\n",
    "        plt.plot(last_epochs, history.history['val_loss'][-10:], label='Validation Loss', color='orange')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss (Last 10 Epochs)')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"Not enough epochs for zoomed plot\", ha='center')\n",
    "    \n",
    "    # 3. 학습 손실과 검증 손실의 차이\n",
    "    plt.subplot(2, 2, 3)\n",
    "    loss_diff = np.array(history.history['val_loss']) - np.array(history.history['loss'])\n",
    "    plt.plot(epochs, loss_diff, label='Val Loss - Train Loss', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss Difference')\n",
    "    plt.title('Difference between Validation and Training Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. 이동 평균 (window=10)을 통한 평활화된 손실 추세\n",
    "    plt.subplot(2, 2, 4)\n",
    "    window = 10\n",
    "    if len(epochs) >= window:\n",
    "        train_ma = [np.mean(history.history['loss'][max(0, i-window):i]) for i in range(1, len(history.history['loss'])+1)]\n",
    "        val_ma = [np.mean(history.history['val_loss'][max(0, i-window):i]) for i in range(1, len(history.history['val_loss'])+1)]\n",
    "        plt.plot(epochs, train_ma, label='Training Loss MA', color='blue', linestyle='--')\n",
    "        plt.plot(epochs, val_ma, label='Validation Loss MA', color='orange', linestyle='--')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss (Moving Average)')\n",
    "        plt.title('Moving Average of Loss (window = 10)')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"Not enough epochs for moving average plot\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Loss 결과물 출력\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.4  # 테스트 데이터 비율 (20%)\n",
    "random_seed = 42  # 랜덤 시드\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model('/home/user/workdir/CMAQ_Emulator/main/src/model/o3_prediction/final_model_main_v2')\n",
    "\n",
    "# 입력 데이터셋 로드\n",
    "pred_emis_data = []\n",
    "dataset_2013 = pd.read_csv('/home/user/workdir/CMAQ_Emulator/main/resources/ctrl/precusor_4att_2013_v2.csv')\n",
    "ctrl_data = pd.concat([dataset_2013], axis=0)\n",
    "ctrl_data = ctrl_data.reset_index(drop=True).values\n",
    "pred_emis_data = ctrl_data[:, :17*2]\n",
    "\n",
    "# 레이블 데이터 로드\n",
    "base_path_2013 = \"/home/user/workdir/CMAQ_Emulator/main/datasets/concentration/2013\"\n",
    "conc_path = []\n",
    "for i in range(1, 120): \n",
    "    conc_path.append(os.path.join(base_path_2013, '1.00', f'ACONC.{i}'))\n",
    "conc_data = []\n",
    "for path in conc_path:\n",
    "    with nc.Dataset(path) as f:\n",
    "        conc_data.append(f.variables['O3'][:].data.squeeze()) \n",
    "conc_data = np.array(conc_data).reshape(len(conc_path), 82, 67, 1)\n",
    "\n",
    "# 여기서, X_emis_train과 y_train은 dummy로 사용\n",
    "X_emis_train, X_emis_test, y_train, y_test = train_test_split(pred_emis_data, conc_data, test_size=test_split, random_state=random_seed)\n",
    "\n",
    "y_preds_scaled = model.predict([X_emis_test])\n",
    "\n",
    "# 스케일러 파라미터 객체 로드\n",
    "scaler = joblib.load('/home/user/workdir/CMAQ_Emulator/main/o3_training/`o3_prediction_origin_v2`.pkl')\n",
    "n_samples = y_preds_scaled.shape[0]  # 테스트 샘플 수\n",
    "y_preds = scaler.inverse_transform(y_preds_scaled.reshape(n_samples, -1))\n",
    "y_preds = y_preds.reshape(y_preds_scaled.shape)\n",
    "\n",
    "y_pred = y_preds.squeeze()\n",
    "y_true = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean values:\", scaler.mean_)\n",
    "print(\"Scale values:\", scaler.scale_)\n",
    "print(\"Variance values:\", scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_expanded = np.repeat(mask[np.newaxis, :, :], repeats=y_true.shape[0], axis=0)\n",
    "pred_conc_map_w_lines = np.where(mask_expanded == 1, y_pred, 0) # 마스킹 적용\n",
    "true_conc_map_w_lines = np.where(mask_expanded == 1, y_true, 0) # 마스킹 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(ax, y_true, y_pred):\n",
    "    r_x, r_y = np.polyfit(y_true, y_pred, 1)\n",
    "    ax.hist2d(\n",
    "        y_true, y_pred,\n",
    "        bins=150, cmap='jet', cmin=1,\n",
    "        norm=mpl.colors.LogNorm(vmin=1, vmax=1000),\n",
    "    )\n",
    "    ax.plot(\n",
    "        y_true, r_x*y_true + r_y,\n",
    "        color='red', label=f\"y={r_x:.4f}x+{r_y:.4f}\")\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    ax.text(\n",
    "        0.05, 0.95, f\"$R^2={r2:.4f}$ \\nSlope={r_x:.4f}\\nIntercept={r_y:.4f}\",\n",
    "        verticalalignment='top', horizontalalignment='left',\n",
    "        transform=ax.transAxes, fontsize=11\n",
    "    )\n",
    "    ax.grid(alpha=0.25)\n",
    "    return ax\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    batch_size = y_true.shape[0]\n",
    "    y_true = y_true.reshape(batch_size, -1)\n",
    "    y_pred = y_pred.reshape(batch_size, -1)\n",
    "    y_norm_err = np.abs(y_true - y_pred) / np.mean(y_true, axis=1, keepdims=True)\n",
    "    y_err_mean = np.mean(y_norm_err, axis=1)\n",
    "    y_err_std = np.percentile(y_norm_err, q=5, axis=1)\n",
    "    return y_err_mean, y_err_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_modi = true_conc_map_w_lines.reshape(-1)\n",
    "y_pred_modi = pred_conc_map_w_lines.reshape(-1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5), dpi=300)\n",
    "axes = plot_scatter(axes, y_true_modi, y_pred_modi)\n",
    "axes.grid(alpha=0.25)\n",
    "axes.set_title(\"True vs. Pred scatter plot\")\n",
    "axes.set_xlabel('True O3 [$\\mu \\mathrm{g}/\\mathrm{m}^3$]')\n",
    "axes.set_ylabel('Pred O3 [$\\mu \\mathrm{g}/\\mathrm{m}^3$]')\n",
    "cbaxes = axes.inset_axes([0.5, 0.2, 0.35, 0.03])\n",
    "cb = plt.colorbar(\n",
    "    mpl.cm.ScalarMappable(norm=mpl.colors.LogNorm(vmin=1, vmax=1000), cmap='jet'),\n",
    "    cax=cbaxes, label='Number of samples', orientation='horizontal')\n",
    "cb.set_label(label='Number of samples', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(13, 6), dpi=300)\n",
    "score, score_std = get_score(true_conc_map_w_lines, pred_conc_map_w_lines)\n",
    "label_text = f'NMAE: {np.mean(score):.3f}±{np.std(score):.3f}'\n",
    "\n",
    "axes.bar(np.arange(y_test.shape[0]), score, yerr=score_std, label=label_text, capsize=2)\n",
    "axes.set_xticks(np.arange(y_test.shape[0]), range(y_test.shape[0]))\n",
    "axes.grid(alpha=0.25)\n",
    "axes.legend()\n",
    "axes.set_title(\"NMAE of Cond. U-Net Nitrate\")\n",
    "axes.set_xlabel('Scenario')\n",
    "axes.set_ylabel('NMAE [%]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_with_white = plt.get_cmap('jet').copy()   # jet 컬러맵 복사\n",
    "cmap_with_white.set_bad('white')               # 마스킹된 부분을 흰색으로\n",
    "\n",
    "def plot_prediction_loss(y_true, y_pred, num_samples=1, indices=-1):\n",
    "    if indices == -1 or indices < 0:\n",
    "        indices = np.random.choice(len(y_true), num_samples, replace=False)\n",
    "    else:\n",
    "        index = indices\n",
    "        indices = [index]\n",
    "    \n",
    "    local_min = min(y_true[indices].min(), y_pred[indices].min())\n",
    "    local_max = max(y_true[indices].max(), y_pred[indices].max())\n",
    "    local_diff = np.abs(y_true[indices] - y_pred[indices])\n",
    "    local_max = max(local_max, local_diff.max())\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes[np.newaxis, :]  # (1, 3) 형태로 맞춤\n",
    "\n",
    "    # 지도 투영 좌표 범위\n",
    "    x_min = -180000 + offset_x\n",
    "    x_max =  414000 + offset_x\n",
    "    y_min = -585000 + offset_y\n",
    "    y_max =  144000 + offset_y\n",
    "\n",
    "    x_ticks = np.linspace(x_min, x_max, 8)\n",
    "    x_labels = [str(i) for i in range(124, 132)]\n",
    "    y_ticks = np.linspace(y_min, y_max, 8)\n",
    "    y_labels = [str(i) for i in range(32, 40)]\n",
    "\n",
    "    # threshold 이하이면 흰색으로 표시\n",
    "    threshold = 0.0005\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        \n",
    "        # (A) True\n",
    "        data_true = y_true[idx][::-1]\n",
    "        masked_true = np.ma.masked_where(data_true <= threshold, data_true)\n",
    "        im_true = axes[i, 0].imshow(\n",
    "            masked_true,\n",
    "            cmap=cmap_with_white,\n",
    "            extent=(x_min, x_max, y_min, y_max),\n",
    "            vmin=threshold,\n",
    "            vmax=local_max \n",
    "        )\n",
    "        ctprvn_proj.boundary.plot(\n",
    "            ax=axes[i, 0], edgecolor='black', facecolor='none', linewidth=1, alpha=0.25\n",
    "        )\n",
    "        axes[i, 0].set_title(f\"True (#{idx})\")\n",
    "        axes[i, 0].set_xlabel('Longitude [°]')\n",
    "        axes[i, 0].set_ylabel('Latitude [°]')\n",
    "        axes[i, 0].set_xlim(x_min, x_max)\n",
    "        axes[i, 0].set_ylim(y_min, y_max)\n",
    "        axes[i, 0].set_xticks(x_ticks)\n",
    "        axes[i, 0].set_yticks(y_ticks)\n",
    "        axes[i, 0].set_xticklabels(x_labels)\n",
    "        axes[i, 0].set_yticklabels(y_labels)\n",
    "        axes[i, 0].grid(alpha=0.25, color='silver')\n",
    "\n",
    "        # (B) Predicted\n",
    "        data_pred = y_pred[idx][::-1]\n",
    "        masked_pred = np.ma.masked_where(data_pred <= threshold, data_pred)\n",
    "\n",
    "        im_pred = axes[i, 1].imshow(\n",
    "            masked_pred,\n",
    "            cmap=cmap_with_white,\n",
    "            extent=(x_min, x_max, y_min, y_max),\n",
    "            vmin=threshold,\n",
    "            vmax=local_max\n",
    "        )\n",
    "        ctprvn_proj.boundary.plot(\n",
    "            ax=axes[i, 1], edgecolor='black', facecolor='none', linewidth=1, alpha=0.25\n",
    "        )\n",
    "        axes[i, 1].set_title(f\"Predicted (#{idx})\")\n",
    "        axes[i, 1].set_xlabel('Longitude [°]')\n",
    "        axes[i, 1].set_ylabel('Latitude [°]')\n",
    "        axes[i, 1].set_xlim(x_min, x_max)\n",
    "        axes[i, 1].set_ylim(y_min, y_max)\n",
    "        axes[i, 1].set_xticks(x_ticks)\n",
    "        axes[i, 1].set_yticks(y_ticks)\n",
    "        axes[i, 1].set_xticklabels(x_labels)\n",
    "        axes[i, 1].set_yticklabels(y_labels)\n",
    "        axes[i, 1].grid(alpha=0.25, color='silver')\n",
    "\n",
    "        # (C) Difference\n",
    "        data_diff = np.abs(y_true[idx] - y_pred[idx])[::-1]\n",
    "        masked_diff = np.ma.masked_where(data_diff <= threshold, data_diff)\n",
    "\n",
    "        im_diff = axes[i, 2].imshow(\n",
    "            masked_diff,\n",
    "            cmap=cmap_with_white,\n",
    "            extent=(x_min, x_max, y_min, y_max),\n",
    "            vmin=threshold,\n",
    "            vmax=local_max\n",
    "        )\n",
    "        ctprvn_proj.boundary.plot(\n",
    "            ax=axes[i, 2], edgecolor='black', facecolor='none', linewidth=1, alpha=0.25\n",
    "        )\n",
    "        axes[i, 2].set_title(f\"Difference (#{idx})\")\n",
    "        axes[i, 2].set_xlabel('Longitude [°]')\n",
    "        axes[i, 2].set_ylabel('Latitude [°]')\n",
    "        axes[i, 2].set_xlim(x_min, x_max)\n",
    "        axes[i, 2].set_ylim(y_min, y_max)\n",
    "        axes[i, 2].set_xticks(x_ticks)\n",
    "        axes[i, 2].set_yticks(y_ticks)\n",
    "        axes[i, 2].set_xticklabels(x_labels)\n",
    "        axes[i, 2].set_yticklabels(y_labels)\n",
    "        axes[i, 2].grid(alpha=0.25, color='silver')\n",
    "\n",
    "    # 서브플롯 간격/레이아웃 조정\n",
    "    plt.subplots_adjust(wspace=-0.4, hspace=0.2)\n",
    "    plt.tight_layout(rect=[0, 0, 0.88, 0.96])\n",
    "\n",
    "    cbar = fig.colorbar(\n",
    "        im_true,\n",
    "        ax=axes.ravel().tolist(),\n",
    "        orientation='vertical',\n",
    "        fraction=0.03,\n",
    "        pad=0.02,\n",
    "        shrink=0.8\n",
    "    )\n",
    "    cbar.set_label('conc. [$\\\\mu \\\\mathrm{g}/\\\\mathrm{m}^3$]')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# ==============================\n",
    "print(\"max:\",np.argmax(score))\n",
    "print(\"min:\",np.argmin(score))\n",
    "plot_prediction_loss(true_conc_map_w_lines, pred_conc_map_w_lines, indices=np.argmin(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
