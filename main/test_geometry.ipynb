{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:27:36.597444: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 17:27:36.627663: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-10 17:27:36.627694: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-10 17:27:36.627713: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 17:27:36.633734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 17:27:37.296572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('/home/user/workdir/main/src/'))))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from src.model.cmaqnet_cond_unet import build_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Map 결과 도출을 위한 지도 파라미터 세팅\n",
    "proj = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "atob = {\n",
    "    0: 'G', 1: 'F', 2: 'K', 3: 'J', 4: 'E', 5: 'D',\n",
    "    6: 'O', 7: 'C', 8: 'A', 9: 'Q', 10: 'P', 11: 'B',\n",
    "    12: 'M', 13: 'L', 14: 'N', 15: 'I', 16: 'H'}\n",
    "region_columns = {\n",
    "    'A': 'Seoul City', 'B': 'Incheon City', 'C': 'Busan City', 'D': 'Daegu City',\n",
    "    'E': 'Gwangju City', 'F': 'Gyeonggi-do', 'G': 'Gangwon-do', 'H': 'Chungbuk-do',\n",
    "    'I': 'Chungnam-do', 'J': 'Gyeongbuk-do', 'K': 'Gyeongnam-do', 'L': 'Jeonbuk-do',\n",
    "    'M': 'Jeonnam-do', 'N': 'Jeju-do', 'O': 'Daejeon City', 'P': 'Ulsan City', 'Q': 'Sejong City'}\n",
    "\n",
    "def get_ctprvn_map() -> gpd.GeoDataFrame:\n",
    "    path = '/home/user/workdir/main/resources/geom/ctp_rvn.shp'\n",
    "    ctprvn = gpd.GeoDataFrame.from_file(path, encoding='cp949')\n",
    "    ctprvn.crs = 'EPSG:5179'\n",
    "    return ctprvn\n",
    "\n",
    "def get_base_raster(ctprvn:gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    points = [Point(i, j)\n",
    "                for i in range(-180000, -180000 + 9000 * 67, 9000)\n",
    "                for j in range(-585000, -585000 + 9000 * 82, 9000)]\n",
    "    grid_data = gpd.GeoDataFrame(points, geometry='geometry', columns=['geometry'])\n",
    "    grid_data.crs = ctprvn.to_crs(proj).crs\n",
    "    grid_data.loc[:,'x_m'] = grid_data.geometry.x\n",
    "    grid_data.loc[:,'y_m'] = grid_data.geometry.y\n",
    "    grid_data.loc[:,'value'] = 0\n",
    "    grid_data.loc[:,'index'] = grid_data.index\n",
    "    return grid_data\n",
    "\n",
    "def get_region_pixel_indices() -> list:\n",
    "    ctprvn = get_ctprvn_map()\n",
    "    grid_data = get_base_raster(ctprvn)\n",
    "\n",
    "    cities = {\n",
    "        0: '강원도', 1: '경기도', 2: '경상남도', 3: '경상북도',\n",
    "        4: '광주광역시', 5: '대구광역시', 6: '대전광역시', 7: '부산광역시',\n",
    "        8: '서울특별시', 9: '세종특별자치시', 10: '울산광역시', 11: '인천광역시',\n",
    "        12: '전라남도', 13: '전라북도', 14: '제주특별자치도', 15: '충청남도',\n",
    "        16: '충청북도'\n",
    "    }\n",
    "\n",
    "    gdf_joined_loc = ['CTPRVN_CD', 'CTP_ENG_NM', 'CTP_KOR_NM', 'index_right0']\n",
    "    gdf_joined = gpd.sjoin(ctprvn, grid_data.to_crs(5179), predicate='contains')\n",
    "\n",
    "    indices = gpd.GeoDataFrame(pd.merge(\n",
    "        left=grid_data, right=gdf_joined.loc[:,gdf_joined_loc], \n",
    "        how='left', left_on='index', right_on='index_right0'\n",
    "    ), geometry='geometry').dropna()\n",
    "    pixel_indices = \\\n",
    "        [[(idx%82, idx//82) for idx in indices.loc[indices.CTP_KOR_NM==cities[region]].index.tolist()]\n",
    "         for region, _ in cities.items()]\n",
    "    return pixel_indices\n",
    "\n",
    "ctprvn = get_ctprvn_map()\n",
    "ctprvn_proj = ctprvn.to_crs(proj)\n",
    "\n",
    "# 건국대(서울대)에서 제공한 대한민국 국토 grid 정보\n",
    "grid_alloc = (\n",
    "    pd.read_csv('/home/user/workdir/main/resources/geom/grid_allocation.csv') # load grid allocation data\n",
    "    .sort_values(by=['Row', 'Column', 'Ratio'], ascending=[True, True, False]) # sort by row, column, ratio\n",
    "    .drop_duplicates(subset=['Row', 'Column'], keep='first') # drop duplicates\n",
    "    .reset_index(drop=True) # reset index\n",
    ")\n",
    "\n",
    "# 정부에서 배포하는 대한민국 국토 grid 정보\n",
    "pixel_indices = get_region_pixel_indices()\n",
    "total_index = []\n",
    "for idx, grids in enumerate(pixel_indices):\n",
    "    for grid in grids:\n",
    "        total_index.append([\n",
    "            grid[1], grid[0], 100.0, atob[idx], region_columns[atob[idx]]\n",
    "        ])\n",
    "total_index = pd.DataFrame(total_index, columns=grid_alloc.columns)\n",
    "\n",
    "# 두 기관에서 주는 grid에 한두픽셀씩 비어있는 부분이 있어, 두 기관 데이터를 모두 참조하여 중복되는 픽셀을 정리 후 최종 국토 grid 정보를 취득\n",
    "grid_alloc = pd.concat([\n",
    "    grid_alloc.drop(columns=['Ratio', 'Region_Name']),\n",
    "    total_index.drop(columns=['Ratio', 'Region_Name'])\n",
    "]).sort_values(by=['Region_Code']).drop_duplicates().reset_index(drop=True)\n",
    "grid_alloc[['Row', 'Column']] = grid_alloc[['Row', 'Column']] - 1\n",
    "\n",
    "row_indices, col_indices = zip(*grid_alloc[['Row', 'Column']].values)\n",
    "offset_x, offset_y = 4500, 4500 # 지도 위치 맞추기\n",
    "\n",
    "# 마스킹 처리\n",
    "mask = np.zeros((82, 67))\n",
    "mask[row_indices, col_indices] = 1\n",
    "\n",
    "cmap_white = mpl.colormaps['jet']\n",
    "cmap_white.set_under('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(series, iqr_factor=1.5):\n",
    "    \"\"\"\n",
    "    series: pd.Series\n",
    "    iqr_factor: 1.5가 기본. (3.0으로 올리면 더 엄격히 outlier 판단)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series (dtype=bool), True이면 이상치\n",
    "    \"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - (iqr_factor * IQR)\n",
    "    upper_bound = Q3 + (iqr_factor * IQR)\n",
    "    \n",
    "    outliers_mask = (series < lower_bound) | (series > upper_bound)\n",
    "    return outliers_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/user/workdir/main/resources/ctrl/precursor_control_2019_4input_scaled_o3.csv')\n",
    "o3_cols = [col for col in df.columns if \"O3_ALL\" in col]\n",
    "df_o3 = df[o3_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O3 열 중 하나라도 outlier로 판정된 행 개수: 4\n",
      "     A_O3_ALL  B_O3_ALL  C_O3_ALL  D_O3_ALL  E_O3_ALL  F_O3_ALL  G_O3_ALL  \\\n",
      "0    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
      "8    0.694954  1.336226  1.048912  1.086317  1.191019  1.081665  1.333931   \n",
      "94   0.547840  1.272830  0.959516  1.022844  1.053369  0.915072  1.267129   \n",
      "115  0.692951  1.339874  1.022420  1.049107  1.170187  1.096962  1.345424   \n",
      "\n",
      "     H_O3_ALL  I_O3_ALL  J_O3_ALL  K_O3_ALL  L_O3_ALL  M_O3_ALL  N_O3_ALL  \\\n",
      "0    1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
      "8    1.226848  1.237194  1.288706  1.242697  1.332488  1.409358  1.470142   \n",
      "94   1.098627  1.147726  1.225385  1.214498  1.275359  1.348776  1.474238   \n",
      "115  1.238689  1.289676  1.303094  1.294918  1.374125  1.411715  1.488215   \n",
      "\n",
      "     O_O3_ALL  P_O3_ALL  Q_O3_ALL  \n",
      "0    1.000000  1.000000  1.000000  \n",
      "8    1.155100  1.121079  1.083791  \n",
      "94   1.025837  1.103844  0.946037  \n",
      "115  1.158474  1.134437  1.098575  \n"
     ]
    }
   ],
   "source": [
    "overall_outliers_mask = np.zeros(len(df_o3), dtype=bool)\n",
    "\n",
    "for col in df_o3.columns:\n",
    "    mask_outliers_col = find_outliers_iqr(df_o3[col], iqr_factor=1.5)\n",
    "    # outlier로 판정된 행(True)는 OR(|=)로 합치기\n",
    "    overall_outliers_mask |= mask_outliers_col\n",
    "\n",
    "# 최종적으로 'O3 컬럼 중 하나라도 IQR 범위를 벗어난' 행\n",
    "df_outliers_o3 = df_o3[overall_outliers_mask]\n",
    "\n",
    "print(\"O3 열 중 하나라도 outlier로 판정된 행 개수:\", len(df_outliers_o3))\n",
    "print(df_outliers_o3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "114    False\n",
       "115     True\n",
       "116    False\n",
       "117    False\n",
       "118    False\n",
       "Name: A_O3_ALL, Length: 119, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_outliers_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이상치 제외 후 df_inliers 크기: (115, 85)\n"
     ]
    }
   ],
   "source": [
    "df_inliers = df[~overall_outliers_mask]  # ~ : 반전\n",
    "print(\"이상치 제외 후 df_inliers 크기:\", df_inliers.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
